# LangCache Shadow Mode

A comprehensive shadow mode implementation for Redis LangCache that enables risk-free validation of semantic caching performance in production environments.

## üéØ Overview

Shadow mode allows you to run LangCache alongside your existing LLM applications without affecting production traffic. It mirrors queries to both your LLM and the semantic cache, logs comparison data (hit rates, latency, similarity scores), and provides detailed analytics - all while serving only LLM responses to end users.

## üèóÔ∏è Architecture

```
User Query
    ‚Üì
Application
    ‚îú‚îÄ‚ñ∫ LLM (Production Response) ‚îÄ‚îÄ‚ñ∫ User
    ‚îî‚îÄ‚ñ∫ LangCache (Shadow Analysis) ‚îÄ‚îÄ‚ñ∫ Logs Only
```

## üåü Key Benefits

‚úÖ **Zero Risk** - Production traffic unaffected
‚úÖ **Real Performance Data** - Actual cache hit rates and latency comparisons
‚úÖ **Trust Building** - Concrete metrics for stakeholders
‚úÖ **Easy Integration** - Minimal code changes required
‚úÖ **Comprehensive Analytics** - Detailed logging and reporting

## üìÅ Repository Structure

```
LangCache-Shadow-Mode/
‚îú‚îÄ‚îÄ wrappers/                    # Language-specific wrapper implementations
‚îÇ   ‚îú‚îÄ‚îÄ python/                  # Python wrapper for shadow mode
‚îÇ   ‚îú‚îÄ‚îÄ nodejs/                  # Node.js wrapper for shadow mode
‚îÇ   ‚îú‚îÄ‚îÄ go/                      # Go wrapper for shadow mode
‚îÇ   ‚îî‚îÄ‚îÄ java/                    # Java wrapper for shadow mode
‚îú‚îÄ‚îÄ langcache-operations/        # LangCache API wrapper service
‚îú‚îÄ‚îÄ examples/                    # Example implementations
‚îÇ   ‚îú‚îÄ‚îÄ flask-app/              # Flask application example
‚îÇ   ‚îú‚îÄ‚îÄ express-app/            # Express.js application example
‚îÇ   ‚îî‚îÄ‚îÄ spring-boot-app/        # Spring Boot application example
‚îú‚îÄ‚îÄ analytics/                   # Analytics and reporting tools
‚îú‚îÄ‚îÄ docs/                       # Documentation
‚îî‚îÄ‚îÄ tests/                      # Test suites
```

## üöÄ Quick Start

### Option 1: Wrapper Functions (Recommended)

#### Python
```python
# Download python/langcache_shadow.py to your project
from langcache_shadow import shadow_llm_call

# Replace your LLM calls with the wrapper
response = shadow_llm_call(
    llm_function=openai.chat.completions.create,
    query="What is AI?",
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "What is AI?"}]
)
```

#### Node.js
```javascript
// Download nodejs/langcache-shadow.js to your project
const { shadowLlmCall } = require('./langcache-shadow');

// Replace your LLM calls with the wrapper
const response = await shadowLlmCall(
    () => openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: query }]
    }),
    query
);
```

### Option 2: API Wrapper Service

```bash
# Run the LangCache operations wrapper
cd langcache-operations/embeddings
python main.py

# Set shadow mode environment variable
export LANGCACHE_SHADOW_MODE=true
```

## ‚öôÔ∏è Configuration

Set these environment variables:

```bash
export LANGCACHE_API_KEY=your-langcache-api-key
export LANGCACHE_CACHE_ID=your-cache-id
export LANGCACHE_BASE_URL=https://api.langcache.com
export REDIS_URL=redis://localhost:6379
export LANGCACHE_SHADOW_MODE=true
```

## üìä Analytics & Reporting

Shadow mode collects comprehensive data for analysis:

```json
{
  "request_id": "uuid4",
  "timestamp": "2025-01-27T15:04:32.123Z",
  "query": "How do I reset my API key?",
  "llm_response": "To reset your API key, go to Settings...",
  "cache_hit": true,
  "cache_response": "You can reset your API key by visiting...",
  "similarity_score": 0.89,
  "cache_latency_ms": 8,
  "llm_latency_ms": 612,
  "model_name": "openai/gpt-4o-mini"
}
```

## üìñ Documentation

- [Getting Started Guide](docs/getting-started.md)
- [Quick Reference](docs/quick-reference.md)
- [Troubleshooting Guide](docs/troubleshooting.md)
- [Wrapper Implementation Guide](docs/wrappers.md)
- [Postman Collection](docs/postman-collection.json)
- [Analytics & Reporting](docs/analytics.md)

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üÜò Support

- [Documentation](docs/)
- [Issues](https://github.com/redis/langcache-shadow-mode/issues)
- [Discussions](https://github.com/redis/langcache-shadow-mode/discussions)
